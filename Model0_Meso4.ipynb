{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79c1e378-a5ab-4f70-8c7b-c334af526864",
   "metadata": {},
   "source": [
    "### Real is natural Disaster pre as train, val, post in test\n",
    "### DF is cycle gan generated images as train, val, test \n",
    "\n",
    "### Zhao in both with respective fake/authentic class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5bae05b3-931f-40d2-a539-213d88d08f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Much of this code was based on Afchar et al (2018) example.py\n",
    "import numpy as np\n",
    "from classifiers import *\n",
    "from pipeline import *\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db426d7f-786c-49d3-8f04-80e30bc5c408",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier = Meso4()\n",
    "classifier.load('weights/Meso4_DF.h5')\n",
    "\n",
    "dataGenerator = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "700a787d-8d74-4912-9d27-470038680d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6104 images belonging to 2 classes.\n",
      "Found 2035 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator?msclkid=811fbc25c69711ecbaa1497e6cd8de5c\n",
    "train_generator = dataGenerator.flow_from_directory(\n",
    "        'ND_cyclegan_zhao\\\\train',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "\n",
    "validation_generator = dataGenerator.flow_from_directory(\n",
    "        'ND_cyclegan_zhao\\\\val',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5398c67e-f10b-43ad-b799-9eea8a1bdb64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "190/190 [==============================] - 431s 2s/step - loss: 0.1625 - accuracy: 0.7641 - val_loss: 0.2578 - val_accuracy: 0.6717\n",
      "Epoch 2/20\n",
      "190/190 [==============================] - 310s 2s/step - loss: 0.0771 - accuracy: 0.8978 - val_loss: 0.4624 - val_accuracy: 0.5376\n",
      "Epoch 3/20\n",
      "190/190 [==============================] - 246s 1s/step - loss: 0.0573 - accuracy: 0.9268 - val_loss: 0.3489 - val_accuracy: 0.5818\n",
      "Epoch 4/20\n",
      "190/190 [==============================] - 244s 1s/step - loss: 0.0461 - accuracy: 0.9410 - val_loss: 0.2438 - val_accuracy: 0.6968\n",
      "Epoch 5/20\n",
      "190/190 [==============================] - 261s 1s/step - loss: 0.0433 - accuracy: 0.9463 - val_loss: 0.3870 - val_accuracy: 0.5523\n",
      "Epoch 6/20\n",
      "190/190 [==============================] - 266s 1s/step - loss: 0.0333 - accuracy: 0.9571 - val_loss: 0.0334 - val_accuracy: 0.9587\n",
      "Epoch 7/20\n",
      "190/190 [==============================] - 256s 1s/step - loss: 0.0309 - accuracy: 0.9595 - val_loss: 0.0643 - val_accuracy: 0.9145\n",
      "Epoch 8/20\n",
      "190/190 [==============================] - 248s 1s/step - loss: 0.0262 - accuracy: 0.9677 - val_loss: 0.4044 - val_accuracy: 0.5818\n",
      "Epoch 9/20\n",
      "190/190 [==============================] - 252s 1s/step - loss: 0.0198 - accuracy: 0.9771 - val_loss: 0.0168 - val_accuracy: 0.9784\n",
      "Epoch 10/20\n",
      "190/190 [==============================] - 255s 1s/step - loss: 0.0210 - accuracy: 0.9741 - val_loss: 0.3108 - val_accuracy: 0.6555\n",
      "Epoch 11/20\n",
      "190/190 [==============================] - 265s 1s/step - loss: 0.0171 - accuracy: 0.9794 - val_loss: 0.3325 - val_accuracy: 0.6486\n",
      "Epoch 12/20\n",
      "190/190 [==============================] - 269s 1s/step - loss: 0.0152 - accuracy: 0.9821 - val_loss: 0.0649 - val_accuracy: 0.9229\n",
      "Epoch 13/20\n",
      "190/190 [==============================] - 253s 1s/step - loss: 0.0151 - accuracy: 0.9812 - val_loss: 0.0093 - val_accuracy: 0.9882\n",
      "Epoch 14/20\n",
      "190/190 [==============================] - 245s 1s/step - loss: 0.0125 - accuracy: 0.9851 - val_loss: 0.4211 - val_accuracy: 0.5720\n",
      "Epoch 15/20\n",
      "190/190 [==============================] - 253s 1s/step - loss: 0.0128 - accuracy: 0.9844 - val_loss: 0.0191 - val_accuracy: 0.9744\n",
      "Epoch 16/20\n",
      "190/190 [==============================] - 257s 1s/step - loss: 0.0091 - accuracy: 0.9885 - val_loss: 0.0256 - val_accuracy: 0.9700\n",
      "Epoch 17/20\n",
      "190/190 [==============================] - 256s 1s/step - loss: 0.0076 - accuracy: 0.9908 - val_loss: 0.0935 - val_accuracy: 0.8968\n",
      "Epoch 18/20\n",
      "190/190 [==============================] - 260s 1s/step - loss: 0.0099 - accuracy: 0.9877 - val_loss: 0.0085 - val_accuracy: 0.9887\n",
      "Epoch 19/20\n",
      "190/190 [==============================] - 251s 1s/step - loss: 0.0104 - accuracy: 0.9874 - val_loss: 0.2654 - val_accuracy: 0.7111\n",
      "Epoch 20/20\n",
      "190/190 [==============================] - 257s 1s/step - loss: 0.0093 - accuracy: 0.9884 - val_loss: 0.1272 - val_accuracy: 0.8663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x18dfe477550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.tensorflow.org/api_docs/python/tf/keras/preprocessing/image/ImageDataGenerator?msclkid=811fbc25c69711ecbaa1497e6cd8de5c\n",
    "# https://stackoverflow.com/questions/57967475/how-to-repeat-data-with-flow-from-directory-in-keras\n",
    "classifier.model.fit(train_generator, \n",
    "                     steps_per_epoch=train_generator.samples/train_generator.batch_size, \n",
    "                     epochs=20, \n",
    "                     validation_data=validation_generator, \n",
    "                     validation_steps=validation_generator.samples/validation_generator.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb9464c5-478d-4b73-a0ad-46fec2937394",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2036 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# post natural disaster\n",
    "\n",
    "test_generator = dataGenerator.flow_from_directory(\n",
    "        'ND_cyclegan_zhao\\\\test',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "978eed69-84a5-4d60-ac92-e74eb0ee191d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64/64 [==============================] - 129s 2s/step - loss: 0.1151 - accuracy: 0.8792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11506957560777664, 0.8791748285293579]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.tensorflow.org/guide/keras/train_and_evaluate\n",
    "classifier.model.evaluate(test_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
